####################################
#             Imports              # 
####################################

using CategoricalArrays
using Clustering
using Distributions
using FillArrays
using LinearAlgebra
using Pipe
using Random: AbstractRNG, GLOBAL_RNG, randperm
using RDatasets
using Statistics
using StatsBase
using StatsBase: sample

include("utilities.jl")

####################################
#             Abstract             #
####################################

abstract type AbstractEMAlgorithm end

# Mixture model algorithms

abstract type AbstractMixtureModel <: AbstractEMAlgorithm end
AMM = AbstractMixtureModel

struct KMeans <: AMM end

struct GMM <: AMM end

# Dawid Skene algorithms

abstract type AbstractDawidSkene <: AbstractEMAlgorithm end
ADS = AbstractDawidSkene

struct FastDawidSkene <: ADS end
FDS = FastDawidSkene

struct DawidSkene <: ADS end
DS = DawidSkene

struct HybridDawidSkene <: ADS end
HDS = HybridDawidSkene

# Other

struct MajorityVoting <: AbstractEMAlgorithm end
MV = MajorityVoting

####################################
#             KMeans               #
####################################

Œ∏_KMeans = Matrix{<:Real}
r_KMeans = Vector{Int}

function init_Œ∏(
    ::KMeans, 
    rng::AbstractRNG, 
    x::Matrix{<:Real}, 
    k::Int
)::Œ∏_KMeans

    n = size(x)[1]
    rand_ids = randperm(rng, n)[1:k]
    Œº = x[rand_ids, :]
    Œ∏ = Œº
    return Œ∏
end

function e_step(alg::KMeans, x::Matrix{<:Real}, Œ∏::Œ∏_KMeans)::r_KMeans
    Œº = Œ∏
    mapslices(x·µ¢ -> compute_r(alg, x·µ¢, Œº), x; dims = 2)[:]
end

function compute_r(::KMeans, x·µ¢::Vector{<:Real}, Œº::Matrix{<:Real})::Int
    mapslices(Œº·µ¢ -> norm(Œº·µ¢ - x·µ¢), Œº; dims = 2)[:] |> argmin
end

function m_step(
    ::KMeans,
    x::Matrix{<:Real},
    r::Vector{Int},
    Œ∏::Œ∏_KMeans
)::Œ∏_KMeans

    Œº = Œ∏
    k = size(Œº)[1]
    r_inds = [findall(equals(r·µ¢), r) for r·µ¢ in 1:k]
    new_Œº_vecs = [
        !isempty(inds) ? mean(x[inds, :], dims = 1)[:] : Œº[i, :] 
        for (i, inds) in enumerate(r_inds)
            ]
    new_Œº_matrix = permutedims(hcat(new_Œº_vecs...))
    Œ∏ = new_Œº_matrix
    return Œ∏
end

####################################
#             GMM                  #
####################################

Œ∏_GMM = Tuple{Vector{<:Real}, Vector{MvNormal}} # Œ†, MvNormal
r_GMM = Matrix{<:Real}

function init_Œ∏(
    ::GMM, 
    rng::AbstractRNG, 
    x::Matrix{<:Real}, 
    k::Int
    )::Œ∏_GMM
    
    N, D = size(x)
    Œº_inds = randperm(rng, N)[1:k]
    Œ† = ones(k) / k
    ùìù = [MvNormal(x[Œº_ind, :], I(D))  for Œº_ind in Œº_inds]
    Œ∏ = (Œ†, ùìù)
    return Œ∏
end

function e_step(alg::GMM, x::Matrix{<:Real}, Œ∏::Œ∏_GMM)::r_GMM
    Œ†, ùìù = Œ∏
    K = length(Œ†)
    r = mapslices(x·µ¢ -> compute_r(alg, x·µ¢, Œ†, ùìù, K), x; dims = 2)
    return r
end

function compute_r(
    ::GMM,
    x·µ¢::Vector{<:Real}, 
    Œ†::Vector{<:Real}, 
    ùìù::Vector{MvNormal}, 
    K::Int
    )::Vector{<:Real}
    
    r = [Œ†[k] * pdf(ùìù[k], x·µ¢) for k in 1:K]
    
    if sum(r) > 0
        return r / sum(r)
    end
    return r
end

function m_step(
    ::GMM, 
    x::Matrix{<:Real}, 
    r::Matrix{<:Real}, 
    Œ∏::Œ∏_GMM
    )::Œ∏_GMM

    Œ†, _ = Œ∏
    K = length(Œ†)
    N, D = size(x)
    N‚Çñ = [sum([r[n, k] for n in 1:N]) for k in 1:K]
    new_Œº = compute_new_Œº(x, r, N, D, K, N‚Çñ)
    new_Œ£ = compute_new_Œ£(x, new_Œº, r, N, K, N‚Çñ)
    new_Œ† = compute_new_Œ†(N, N‚Çñ)
    new_ùìù = [MvNormal(new_Œº[k, :], new_Œ£[k] + I * 1e-7) for k in 1:K]
    new_Œ∏ = (new_Œ†, new_ùìù)
    return new_Œ∏
end

#TODO: functionalize
function compute_new_Œº(
    x::Matrix{<:Real}, 
    r::Matrix{<:Real}, 
    N::Int, 
    D::Int, 
    K::Int, 
    N‚Çñ::Vector{<:Real}
    )::Matrix{<:Real}

    new_Œº = zeros(K, D)
    for k in 1:K
        new_Œº‚Çñ = [r[n, k] * x[n, :] for n in 1:N]
        new_Œº[k, :] = sum(permutedims(hcat(new_Œº‚Çñ...)), dims=1) / N‚Çñ[k]
    end
    return new_Œº
end

function compute_new_Œ£(
    x::Matrix{<:Real}, 
    new_Œº::Matrix{<:Real}, 
    r::Matrix{<:Real}, 
    N::Int, 
    K::Int, 
    N‚Çñ::Vector{<:Real}
    )::Vector{Matrix{<:Real}}
    
    new_Œ£ = []
    for k in 1:K
        new_Œ£‚Çñ = Hermitian(sum([r[n, k] * (x[n, :] - new_Œº[k, :]) * transpose(x[n, :] - new_Œº[k, :])  #TODO: tranpose with '
        for n in 1:N]) / N‚Çñ[k])
        push!(new_Œ£, convert(Matrix{Float64}, new_Œ£‚Çñ))
    end
    return new_Œ£
    
end

function compute_new_Œ†(N::Int, N‚Çñ::Vector{<:Real})::Vector{<:Real}
    [N‚Çñ[k] / N for k in 1:length(N‚Çñ)]
end

####################################
#             Dawid-Skene          #
####################################

function calc_likelihood(::ADS, counts, class_marginals, error_rates)
    nPatients, nObservers, nClasses = size(counts)
    log_L = 0.0
    
    for i in 1:nPatients
        patient_likelihood = 0.0
        for j in 1:nClasses
            class_prior = class_marginals[j]
            patient_class_likelihood = prod(error_rates[:, j, :] .^ counts[i, :, :])
            patient_class_posterior = class_prior * patient_class_likelihood
            patient_likelihood += patient_class_posterior
        end 
        temp = log_L + log(patient_likelihood)
        if isnan(temp) || isnothing(temp) || isinf(temp)
            error("Invalid temp value: $temp")
        end
        log_L = temp
    end
    return log_L
end

function initialize_question_classes(::FDS, counts::Array{<:Real, 3})
    nQuestions, nParticipants, nClasses = size(counts)
    response_sums = reshape(sum(counts, dims = 2), (nQuestions, nClasses))
    # display(response_sums)
    question_classes = zeros(nQuestions, nClasses)
    # if mode == "FDS" ||
    for p in 1:nQuestions
        maxval = maximum(response_sums[p, :])
        maxinds = argwhere(response_sums[p, :], ==(maxval))
        question_classes[p, sample(maxinds, 1)[1]] = 1 #TODO: add RNG
    end
    # else 
    return question_classes
end

function m_step(
    ::FDS,
    counts, 
    question_classes
)
    nQuestions, nParticipants, nClasses = size(counts)
    class_marginals = sum(question_classes, dims = 1) ./ nQuestions
    error_rates = zeros(nParticipants, nClasses, nClasses)
    for k in 1:nParticipants
        for j in 1:nClasses
            for l in 1:nClasses
                error_rates[k, j, l] = question_classes[:, j]' * counts[:, k, l]
            end
            sum_over_responses = sum(error_rates[k, j, :])
            if sum_over_responses > 0
                error_rates[k, j, :] = error_rates[k, j, :] / sum_over_responses
            end
        end
    end
    return class_marginals, error_rates
end

function e_step(
    ::FDS,
    counts,
    class_marginals, 
    error_rates
)
    nQuestions, nParticipants, nClasses = size(counts)
    question_classes = zeros(nQuestions, nClasses)
    final_classes = zeros(nQuestions, nClasses)
    for i in 1:nQuestions
        for j in 1:nClasses
            estimate = class_marginals[j] * prod(error_rates[:, j, :] .^ counts[i, :, :])
            question_classes[i, j] = estimate
        end
        # if mode ...
        maxval = maximum(question_classes[i, :])
        maxinds = argwhere(question_classes[i, :], ==(maxval))
        final_classes[i, sample(maxinds, 1)[1]] = 1
    end
    return final_classes
end

function em(
    alg::ADS,
    counts::AbstractArray{<:Real, 3}
    # args: algorithm and verbose #TODO: implement
    ;
    tol = .0001,
    CM_tol = .005,
    max_iter = 100,
    verbose::Bool=true
)

    # Initialize
    question_classes = initialize_question_classes(alg, counts)
    nIter = 0
    converged = false
    old_class_marginals = nothing
    old_error_rates = nothing
    # total_time = 0
    log_L = nothing
    while !converged
        nIter += 1
        class_marginals, error_rates = m_step(alg, counts, question_classes)
        question_classes = e_step(alg, counts, class_marginals, error_rates)
        log_L = calc_likelihood(alg, counts, class_marginals, error_rates)
        
        # Check for convergence
        if old_class_marginals ‚â† nothing
            class_marginals_diff = sum(abs.(class_marginals - old_class_marginals))
            error_rates_diff = sum(abs.(error_rates - old_error_rates))
            # if verbose 
            if class_marginals_diff < tol || nIter >= max_iter
                converged = true
            end #elif mode == "H"
        end # else if verbose
        old_class_marginals = class_marginals
        old_error_rates = error_rates
        if verbose
            @show nIter
            @show log_L
        end
    end
    result = @pipe argmax(question_classes, dims = 2)[:] |> map(x -> x[2], _)
end



####################################
#             Generic EM           #
####################################

function em(
    alg::AbstractMixtureModel, 
    x::Matrix{<:Real};
    k::Int=3,
    n_steps::Int=10
    )::Tuple{Vector, Vector}
    Œ∏ = init_Œ∏(alg, GLOBAL_RNG, x, k)
    r_history = []
    Œ∏_history = []
    for step in 1:n_steps
        r = e_step(alg, x, Œ∏)
        Œ∏ = m_step(alg, x, r, Œ∏)
        push!(r_history, r)
        push!(Œ∏_history, Œ∏)
    end

    return Œ∏_history, r_history
end

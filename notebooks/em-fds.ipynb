{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the module for class initialization functions\n",
    "\n",
    "using ExpectationMaximization\n",
    "import ExpectationMaximization: initialize_class_assignments, m_step\n",
    "\n",
    "# Make sure that this notebook is run from the main directory\n",
    "\n",
    "endswith(pwd(), \"/notebooks\") && cd(\"..\")\n",
    "PROJECT_PATH = pwd()\n",
    "\n",
    "include(\"$PROJECT_PATH/src/load_datasets.jl\")\n",
    "\n",
    "dataset = load_rte();\n",
    "\n",
    "# [questions x one-hot classes]\n",
    "class_assignments = initialize_class_assignments(FDS(), dataset.crowd_counts);\n",
    "\n",
    "# [question x annotators x classes]\n",
    "counts = dataset.crowd_counts;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra: normalize\n",
    "\n",
    "function init_param(counts)\n",
    "    class_marginals, error_rates = m_step(FDS(), counts, initialize_class_assignments(FDS(), counts))\n",
    "    return normalize(class_marginals[:], 1)\n",
    "end\n",
    "\n",
    "second(x) = x[2]\n",
    "third(x) = x[3]\n",
    "\n",
    "\"\"\"\n",
    "element-wise multiplication in order to remove annotators that didn't answer the question\n",
    "\"\"\"\n",
    "function onehot_choices_to_categorical(x::Array{<:Real, 3})::Matrix{Int}\n",
    "    third.(argmax(x; dims=3)[:, :, 1]) .* maximum(x; dims=3)[:, :, 1]\n",
    "end\n",
    "\n",
    "Q, A, O = size(counts) # questions, answers, options\n",
    "choices = onehot_choices_to_categorical(counts)\n",
    "class_assignments = second.(argmax(initialize_class_assignments(FDS(), counts); dims=2)[:, 1])\n",
    "class_marginals = init_param(counts)\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "em_fds (generic function with 2 methods)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Distributions\n",
    "using LogExpFunctions\n",
    "using Turing\n",
    "\n",
    "@model function em_fds(\n",
    "    choices::Matrix{Int}, # [Q x A]\n",
    "    unnormalized_class_marginals::Vector{<:Real} # [O] (probability vector)\n",
    ")\n",
    "    # Get dimensions\n",
    "    Q, A = size(choices) # questions, answers\n",
    "    O = length(unnormalized_class_marginals) # options\n",
    "\n",
    "    # eq (4)\n",
    "    p_Y = Categorical(softmax(unnormalized_class_marginals))\n",
    "    \n",
    "    # sample answer sheet\n",
    "    Ys ~ filldist(p_Y, Q)\n",
    "\n",
    "    # @show Ys\n",
    "    \n",
    "    #TODO: \n",
    "    # 1. try using broadcasting for S and T\n",
    "    # 2. figure out NaN problem\n",
    "    # 3. get initial version pushed early next week (Sunday)\n",
    "\n",
    "    # eq (3)\n",
    "\n",
    "    # S = [for a in 1:A, o in 1:O]\n",
    "\n",
    "    S = zeros(Int, A, O) # [A x O]\n",
    "    for a in 1:A, o in 1:O\n",
    "        # {i | Yᵢ = c ∧ a has answered question i}\n",
    "        S[a, o] = length([q for q in 1:Q \n",
    "                          if Ys[q] == o # Yᵢ = c\n",
    "                          && choices[q, a] != 0 # a has answered question i\n",
    "                          ]) \n",
    "    end\n",
    "\n",
    "    T = zeros(Int, A, O, O) # [A x O x O]\n",
    "    for a in 1:A, o1 in 1:O, o2 in 1:O\n",
    "        # {i | Yᵢ = c ∧ a has answered cₐ on question i}\n",
    "        T[a, o1, o2] = length([q for q in 1:Q \n",
    "                               if Ys[q] == o1 # Yᵢ = c\n",
    "                               && choices[q, a] == o2 # a has answered cₐ on question i\n",
    "                               ])\n",
    "    end\n",
    "    \n",
    "    error_rates = T ./ S\n",
    "\n",
    "    @show error_rates\n",
    "    \n",
    "    p_c_given_Y = [Categorical(error_rates[a, o, :]) for a in 1:A, o in 1:O]\n",
    "    for q in 1:Q, a in 1:A\n",
    "        choices[q, a] == 0 && continue\n",
    "        choices[q, a] ~ p_c_given_Y[a, Ys[q]]\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_obj (generic function with 1 method)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_latent(chn; keep_pct=.5, use_every=1)\n",
    "    # [latent_dim, num_samples]\n",
    "    chn.value.data[floor(Int, keep_pct * end) : use_every : end, 1:800] |> Matrix{Int} |> transpose\n",
    "end\n",
    "\n",
    "function make_obj(latent)\n",
    "    function obj(unnormalized_class_marginals)\n",
    "        normalized_class_marginals = normalize(unnormalized_class_marginals, 1)\n",
    "        return -mean([\n",
    "            logjoint(em_fds(choices, normalized_class_marginals), (; Ys=Ys))\n",
    "            for Ys in eachcol(latent)\n",
    "            ])\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Random\n",
    "# using ProgressMeter\n",
    "# using Optim\n",
    "\n",
    "# Random.seed!(42)\n",
    "\n",
    "# num_particles = 20\n",
    "# num_samples = 20\n",
    "# num_iterations = 10\n",
    "# sampler = PG(num_particles)\n",
    "\n",
    "# class_marginals = init_param(counts)\n",
    "# trace = (chn=[], opt=[])\n",
    "\n",
    "# @showprogress for i in 1:num_iterations\n",
    "#     # E-step\n",
    "#     chn = sample(em_fds(choices, class_marginals), sampler, num_samples; progress=false)\n",
    "#     push!(trace.chn, chn)\n",
    "    \n",
    "#     # M-step\n",
    "#     opt = optimize(make_obj(get_latent(chn)), class_marginals)\n",
    "#     push!(trace.opt, opt)\n",
    "#     class_marginals = opt.minimizer\n",
    "\n",
    "#     # Report\n",
    "#     println(\"$i: $(opt.minimum) | $(chn.logevidence)\")\n",
    "# end\n",
    "\n",
    "# using Dates\n",
    "# using JLD\n",
    "# save(\"./trace_$(split(string(now()), '.')[1]).jld\", \"trace\", trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = load(\"./trace.jld\")[\"trace\"]\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((:chn, :opt), 4, 4)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace|>typeof|>fieldnames, length(trace.chn), length(trace.opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_marginals = trace.opt[end].minimizer\n",
    "chn = sample(em_fds(choices, class_marginals), sampler, num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rates = [0.5769230769230769 0.7857142857142857; 0.4891304347826087 0.4722222222222222; 0.4166666666666667 0.625; 0.48295454545454547 0.4423076923076923; 0.4166666666666667 0.625; 0.5990888382687927 0.6551724137931034; 0.5396825396825397 0.5675675675675675; 0.7331288343558282 0.7897196261682243; 0.8363273453093812 0.782608695652174; 0.7794117647058824 0.75; 0.49122807017543857 0.4782608695652174; 0.28 0.26666666666666666; 0.25 0.0; 0.4666666666666667 0.3; 0.41935483870967744 0.48936170212765956; 0.6 0.676923076923077; 0.4375 0.75; 0.8518518518518519 0.8461538461538461; 0.9333333333333333 0.8; 0.4 0.8; 0.4722222222222222 0.5833333333333334; 0.5 0.5; 0.4666666666666667 0.0; 0.42857142857142855 0.3888888888888889; 0.4666666666666667 0.2; 0.4 0.4; 0.6 0.2; 0.5333333333333333 0.2; 0.5 0.3333333333333333; 0.42857142857142855 0.3333333333333333; 0.45454545454545453 0.4444444444444444; 0.5555555555555556 0.6363636363636364; 0.48484848484848486 0.5185185185185185; 0.4444444444444444 0.45454545454545453; 0.35714285714285715 0.5; 0.35714285714285715 0.16666666666666666; 0.35714285714285715 0.25; 0.2857142857142857 0.5; 0.7142857142857143 0.5; 0.6666666666666666 0.45454545454545453; 0.47368421052631576 0.2857142857142857; 0.45161290322580644 0.1724137931034483; 0.8888888888888888 0.45454545454545453; 0.7333333333333333 0.8; 0.6666666666666666 0.375; 0.6666666666666666 0.4; 0.3333333333333333 0.40625; 0.3076923076923077 0.8571428571428571; 0.8461538461538461 1.0; 0.23076923076923078 0.5714285714285714; 0.4230769230769231 0.35714285714285715; 0.6153846153846154 0.8571428571428571; 0.6153846153846154 0.7142857142857143; 0.5217391304347826 0.5294117647058824; 0.5 0.625; 0.5849056603773585 0.6666666666666666; 0.4166666666666667 0.5; 0.3333333333333333 0.75; 0.5 0.625; 0.5 0.625; 0.3 0.5; 0.3 0.3; 0.1 0.4; 0.5 0.4; 0.0 0.2; 0.5625 0.5; 0.5625 0.25; 0.4523809523809524 0.4444444444444444; 0.6875 0.5; 0.375 0.5; 0.5625 0.5; 0.6153846153846154 0.7142857142857143; 0.6153846153846154 0.5714285714285714; 0.38461538461538464 0.5714285714285714; 0.46153846153846156 0.5714285714285714; 0.42857142857142855 0.3333333333333333; 0.5714285714285714 0.8333333333333334; 0.5 0.6666666666666666; 0.6428571428571429 0.8333333333333334; 0.7857142857142857 0.6666666666666666; 0.6363636363636364 0.6666666666666666; 0.18181818181818182 0.3333333333333333; 0.5909090909090909 0.5555555555555556; 0.6363636363636364 0.6666666666666666; 0.3 0.3; 0.625 0.375; 0.5 0.6; 1.0 1.0; 0.7692307692307693 0.42857142857142855; 0.6153846153846154 0.42857142857142855; 0.7692307692307693 0.5714285714285714; 0.5 0.16666666666666666; 0.5714285714285714 0.3333333333333333; 0.5714285714285714 0.16666666666666666; 0.2727272727272727 0.5555555555555556; 0.18181818181818182 0.6666666666666666; 0.2727272727272727 0.5555555555555556; 0.18181818181818182 0.6666666666666666; 0.75 0.5; 0.5 0.3; 0.4358974358974359 0.2857142857142857; 0.42857142857142855 0.16666666666666666; 0.14285714285714285 0.0; 0.35714285714285715 0.0; 0.2857142857142857 0.16666666666666666; 0.42857142857142855 0.16666666666666666; 0.2857142857142857 0.15789473684210525; 0.4166666666666667 0.25; 0.3333333333333333 0.25; 0.1111111111111111 0.09090909090909091; 0.1111111111111111 0.09090909090909091; 0.3333333333333333 0.18181818181818182; 0.3333333333333333 0.5; 0.5 0.625; 0.5 0.625; 0.5 0.625; 0.4166666666666667 0.625; 0.4 0.6; 0.38461538461538464 0.42857142857142855; 0.4 0.6; 0.7272727272727273 0.6666666666666666; 0.5769230769230769 0.7142857142857143; 0.45454545454545453 0.5555555555555556; 0.5757575757575758 0.6296296296296297; 0.5416666666666666 0.4375; 0.4 0.6; 0.4 0.4; 0.48 0.7333333333333333; 0.5 0.2; 0.4 0.2; 0.3 0.1; 0.3 0.1; 0.6428571428571429 0.5; 0.42857142857142855 0.3333333333333333; 0.38461538461538464 0.5714285714285714; 0.5384615384615384 0.5714285714285714; 0.38461538461538464 0.42857142857142855; 0.38461538461538464 0.5714285714285714; 0.5714285714285714 0.5; 0.5 0.16666666666666666; 0.5714285714285714 0.3333333333333333; 0.4666666666666667 0.4; 0.3333333333333333 0.6; 0.5333333333333333 0.4; 0.391304347826087 0.5882352941176471; 0.5 0.6; 0.7 0.7; 0.8 0.4; 0.5 0.6; 0.3076923076923077 0.42857142857142855; 0.07692307692307693 0.2857142857142857; 0.5384615384615384 0.5714285714285714; 0.625 0.6666666666666666; 0.5 0.5833333333333334; 0.5 0.5; 0.875 0.8333333333333334; 0.5 0.5833333333333334; 0.36363636363636365 0.3333333333333333; 0.2727272727272727 0.5555555555555556; 0.45454545454545453 0.3333333333333333; 0.6363636363636364 0.1111111111111111; 0.6666666666666666 0.3125; 0.6923076923076923 0.2857142857142857; 0.6153846153846154 0.2857142857142857;;; 0.4230769230769231 0.21428571428571427; 0.5108695652173914 0.5277777777777778; 0.5833333333333334 0.375; 0.5170454545454546 0.5576923076923077; 0.5833333333333334 0.375; 0.4009111617312073 0.3448275862068966; 0.4603174603174603 0.43243243243243246; 0.2668711656441718 0.2102803738317757; 0.16367265469061876 0.21739130434782608; 0.22058823529411764 0.25; 0.5087719298245614 0.5217391304347826; 0.72 0.7333333333333333; 0.75 1.0; 0.5333333333333333 0.7; 0.5806451612903226 0.5106382978723404; 0.4 0.3230769230769231; 0.5625 0.25; 0.14814814814814814 0.15384615384615385; 0.06666666666666667 0.2; 0.6 0.2; 0.5277777777777778 0.4166666666666667; 0.5 0.5; 0.5333333333333333 1.0; 0.5714285714285714 0.6111111111111112; 0.5333333333333333 0.8; 0.6 0.6; 0.4 0.8; 0.4666666666666667 0.8; 0.5 0.6666666666666666; 0.5714285714285714 0.6666666666666666; 0.5454545454545454 0.5555555555555556; 0.4444444444444444 0.36363636363636365; 0.5151515151515151 0.48148148148148145; 0.5555555555555556 0.5454545454545454; 0.6428571428571429 0.5; 0.6428571428571429 0.8333333333333334; 0.6428571428571429 0.75; 0.7142857142857143 0.5; 0.2857142857142857 0.5; 0.3333333333333333 0.5454545454545454; 0.5263157894736842 0.7142857142857143; 0.5483870967741935 0.8275862068965517; 0.1111111111111111 0.5454545454545454; 0.26666666666666666 0.2; 0.3333333333333333 0.625; 0.3333333333333333 0.6; 0.6666666666666666 0.59375; 0.6923076923076923 0.14285714285714285; 0.15384615384615385 0.0; 0.7692307692307693 0.42857142857142855; 0.5769230769230769 0.6428571428571429; 0.38461538461538464 0.14285714285714285; 0.38461538461538464 0.2857142857142857; 0.4782608695652174 0.47058823529411764; 0.5 0.375; 0.41509433962264153 0.3333333333333333; 0.5833333333333334 0.5; 0.6666666666666666 0.25; 0.5 0.375; 0.5 0.375; 0.7 0.5; 0.7 0.7; 0.9 0.6; 0.5 0.6; 1.0 0.8; 0.4375 0.5; 0.4375 0.75; 0.5476190476190477 0.5555555555555556; 0.3125 0.5; 0.625 0.5; 0.4375 0.5; 0.38461538461538464 0.2857142857142857; 0.38461538461538464 0.42857142857142855; 0.6153846153846154 0.42857142857142855; 0.5384615384615384 0.42857142857142855; 0.5714285714285714 0.6666666666666666; 0.42857142857142855 0.16666666666666666; 0.5 0.3333333333333333; 0.35714285714285715 0.16666666666666666; 0.21428571428571427 0.3333333333333333; 0.36363636363636365 0.3333333333333333; 0.8181818181818182 0.6666666666666666; 0.4090909090909091 0.4444444444444444; 0.36363636363636365 0.3333333333333333; 0.7 0.7; 0.375 0.625; 0.5 0.4; 0.0 0.0; 0.23076923076923078 0.5714285714285714; 0.38461538461538464 0.5714285714285714; 0.23076923076923078 0.42857142857142855; 0.5 0.8333333333333334; 0.42857142857142855 0.6666666666666666; 0.42857142857142855 0.8333333333333334; 0.7272727272727273 0.4444444444444444; 0.8181818181818182 0.3333333333333333; 0.7272727272727273 0.4444444444444444; 0.8181818181818182 0.3333333333333333; 0.25 0.5; 0.5 0.7; 0.5641025641025641 0.7142857142857143; 0.5714285714285714 0.8333333333333334; 0.8571428571428571 1.0; 0.6428571428571429 1.0; 0.7142857142857143 0.8333333333333334; 0.5714285714285714 0.8333333333333334; 0.7142857142857143 0.8421052631578947; 0.5833333333333334 0.75; 0.6666666666666666 0.75; 0.8888888888888888 0.9090909090909091; 0.8888888888888888 0.9090909090909091; 0.6666666666666666 0.8181818181818182; 0.6666666666666666 0.5; 0.5 0.375; 0.5 0.375; 0.5 0.375; 0.5833333333333334 0.375; 0.6 0.4; 0.6153846153846154 0.5714285714285714; 0.6 0.4; 0.2727272727272727 0.3333333333333333; 0.4230769230769231 0.2857142857142857; 0.5454545454545454 0.4444444444444444; 0.42424242424242425 0.37037037037037035; 0.4583333333333333 0.5625; 0.6 0.4; 0.6 0.6; 0.52 0.26666666666666666; 0.5 0.8; 0.6 0.8; 0.7 0.9; 0.7 0.9; 0.35714285714285715 0.5; 0.5714285714285714 0.6666666666666666; 0.6153846153846154 0.42857142857142855; 0.46153846153846156 0.42857142857142855; 0.6153846153846154 0.5714285714285714; 0.6153846153846154 0.42857142857142855; 0.42857142857142855 0.5; 0.5 0.8333333333333334; 0.42857142857142855 0.6666666666666666; 0.5333333333333333 0.6; 0.6666666666666666 0.4; 0.4666666666666667 0.6; 0.6086956521739131 0.4117647058823529; 0.5 0.4; 0.3 0.3; 0.2 0.6; 0.5 0.4; 0.6923076923076923 0.5714285714285714; 0.9230769230769231 0.7142857142857143; 0.46153846153846156 0.42857142857142855; 0.375 0.3333333333333333; 0.5 0.4166666666666667; 0.5 0.5; 0.125 0.16666666666666666; 0.5 0.4166666666666667; 0.6363636363636364 0.6666666666666666; 0.7272727272727273 0.4444444444444444; 0.5454545454545454 0.6666666666666666; 0.36363636363636365 0.8888888888888888; 0.3333333333333333 0.6875; 0.3076923076923077 0.7142857142857143; 0.38461538461538464 0.7142857142857143]\n",
    "p_c_given_Y = [Categorical(error_rates[a, o, :]) for a in 1:A, o in 1:O]\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 1072)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ys = [1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 2, 2, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 2, 2, 1, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 2, 2, 1, 1, 2, 1, 1, 1, 2, 1, 2, 2, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 2, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 2, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 2, 2, 2, 2, 1, 1, 2, 1, 1, 2, 2, 1, 2, 1, 1, 1, 2, 2, 1, 1, 2, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2, 2, 2, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 2, 2, 1, 2, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 2, 2, 1, 1, 2, 1, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 2]\n",
    ";\n",
    "length(Ys), sum(Ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "false"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = zeros(Int, A, O) # [A x O]\n",
    "for a in 1:A, o in 1:O\n",
    "    # {i | Yᵢ = c ∧ a has answered question i}\n",
    "    S[a, o] = length([q for q in 1:Q \n",
    "                        if Ys[q] == o # Yᵢ = c\n",
    "                        && choices[q, a] != 0 # a has answered question i\n",
    "                        ]) \n",
    "end\n",
    "S_ = 1\n",
    "S == S_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(164, 2)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(164, 2, 2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = zeros(Int, A, O, O) # [A x O x O]\n",
    "for a in 1:A, o1 in 1:O, o2 in 1:O\n",
    "    # {i | Yᵢ = c ∧ a has answered cₐ on question i}\n",
    "    T[a, o1, o2] = length([q for q in 1:Q \n",
    "                            if Ys[q] == o1 # Yᵢ = c\n",
    "                            && choices[q, a] == o2 # a has answered cₐ on question i\n",
    "                            ])\n",
    "end\n",
    "size(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rates  = T ./ S\n",
    "p_c_given_Y = [Categorical(error_rates[a, o, :]) for a in 1:A, o in 1:O]\n",
    ";\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q = 800\n",
      "A = 164\n",
      "O = 2\n"
     ]
    }
   ],
   "source": [
    "Q, A = size(choices)\n",
    "O = length(class_marginals);\n",
    "println(\"Q = $Q\\nA = $A\\nO = $O\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching ~(::Product{Discrete, Categorical{Float64, Vector{Float64}}, FillArrays.Fill{Categorical{Float64, Vector{Float64}}, 1, Tuple{Base.OneTo{Int64}}}}, ::Product{Discrete, Categorical{Float64, Vector{Float64}}, FillArrays.Fill{Categorical{Float64, Vector{Float64}}, 1, Tuple{Base.OneTo{Int64}}}})",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching ~(::Product{Discrete, Categorical{Float64, Vector{Float64}}, FillArrays.Fill{Categorical{Float64, Vector{Float64}}, 1, Tuple{Base.OneTo{Int64}}}}, ::Product{Discrete, Categorical{Float64, Vector{Float64}}, FillArrays.Fill{Categorical{Float64, Vector{Float64}}, 1, Tuple{Base.OneTo{Int64}}}})",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[44]:3",
      " [2] eval",
      "   @ ./boot.jl:373 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1196"
     ]
    }
   ],
   "source": [
    "class_marginals = trace.opt[end].minimizer\n",
    "p_Y = Categorical(softmax(class_marginals))\n",
    "Ys ~ filldist(p_Y, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: using Dates.second in module Main conflicts with an existing identifier.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2022-09-18T10:00:04.032"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 54 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m87.521 ms\u001b[22m\u001b[39m … \u001b[35m100.229 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 7.39%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m92.469 ms               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m94.016 ms\u001b[22m\u001b[39m ± \u001b[32m  4.175 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m3.75% ± 3.90%\n",
       "\n",
       "  \u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\u001b[39m \u001b[39m \u001b[39m▁\u001b[39m \u001b[39m▁\u001b[39m \u001b[39m \u001b[39m▄\u001b[39m \u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▄\u001b[34m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[32m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m█\u001b[39m▄\u001b[39m \u001b[39m▁\u001b[39m \u001b[39m \u001b[39m▁\u001b[39m \u001b[39m \u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m▆\u001b[39m▁\u001b[39m▁\u001b[39m█\u001b[39m▆\u001b[39m▆\u001b[39m█\u001b[39m▁\u001b[39m█\u001b[39m▆\u001b[39m▁\u001b[39m█\u001b[39m▆\u001b[39m█\u001b[39m█\u001b[39m▆\u001b[39m▁\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m█\u001b[34m▁\u001b[39m\u001b[39m▆\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[32m▁\u001b[39m\u001b[39m▁\u001b[39m▆\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▁\u001b[39m▆\u001b[39m▁\u001b[39m█\u001b[39m█\u001b[39m▆\u001b[39m█\u001b[39m▆\u001b[39m▆\u001b[39m█\u001b[39m▆\u001b[39m▆\u001b[39m█\u001b[39m▆\u001b[39m▁\u001b[39m▆\u001b[39m \u001b[39m▁\n",
       "  87.5 ms\u001b[90m         Histogram: frequency by time\u001b[39m          100 ms \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m30.52 MiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m1297043\u001b[39m."
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark model.f(\n",
    "    model,\n",
    "    Turing.VarInfo(model),\n",
    "    Turing.SamplingContext(\n",
    "        Random.GLOBAL_RNG, Turing.SampleFromPrior(), Turing.DefaultContext(),\n",
    "    ),\n",
    "    model.args...\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
